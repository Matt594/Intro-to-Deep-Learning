{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST Convolutional Neural Network",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matt594/Intro-to-Deep-Learning/blob/master/MNIST_Convolutional_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "0wt9uivsDFPJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Interpretting a Convolutional Neural Network**\n",
        "\n",
        "This notebook is a breakdown of convolutional neural networks with Keras. The goal of this notebook is to provide a compact reference for those with an entirely fresh background to computer science and/or machine learning. This is also just one out of three notebooks; the other two notebooks tackle multi-layer perceptrons (which I recommend viewing first) and recurrent neural networks.\n",
        "\n",
        "A convolutional neural network is a deep learning structure commonly used to classify, or categorize, images. Thus, when an image is fed into a convolutional neural network, it's function is to determine what category the image fits in by looking for specific patterns. For people, this task is very simple; we can identify cars, birds, landscapes, hats, and more at a glance of an image. However, making an algorithm that quantifies patterns in images to 'learn' what they are is a different story. The convolutional neural network in this notebook will classify different articles of clothing into one of ten categories.\n",
        "\n",
        "In each cell, I will attempt to provide a grounds-up explanation of the cell's contents, so the cell explanations may stray from machine learning concepts time to time and repeat content provided by the two other notebooks. Again, the goal of this notebook is to provide a reference for anyone to understand while remaining compact. If there's a topic you'd like to look into more, I've provided some extra sources of information in each cell.\n",
        "\n",
        "Description of code cells should include:\n",
        "1. Title: What topic(s) are being covered in the cell\n",
        "2. Purpose: Goal of the cell\n",
        "3. Execution: What the code is doing\n",
        "4. Vocabulary/Concepts: Terminology and concepts for computer science of machine learning\n",
        "5. General: Common principle/practice regarding cell operations and code\n",
        "6. Interpretating Code: A guide to deciphering the cell's code\n",
        "7. External Information: Sources for more information"
      ]
    },
    {
      "metadata": {
        "id": "nZnTM9GHul60",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "07e2d448-e44c-48e4-93a3-10704f906a83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Import necessary libraries\n",
        "import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "OZgCQ5mMQLAr"
      },
      "cell_type": "markdown",
      "source": [
        "# **Import Statements**\n",
        "\n",
        "This first cell imports modules to make the coding process simpler. With pre-made modules, the programmer doesn't have to reinvent the wheel. They can spend more time creating an applicable program and less time creating a modular foundation.\n",
        "\n",
        "**Vocabulary/Concepts**\n",
        "*   Importing...Makes data accessible from another module\n",
        "  *   Module.......Collection of pre-made methods, classes, or programs\n",
        "\n",
        "**Execution**\n",
        "\n",
        "When a program calls for an import, the program searches for a module of the requested name on a system path.Though, before importing, modules must be downloaded or created so they have an address on the machine where the program is running. Once again, these are crucial because they'll save us time when creating our network; we won't need to create one from scratch.\n",
        "\n",
        "**General** \n",
        "*   When importing, distinguish what modules must be used. No program needs to know every module on your machine.\n",
        "*   Chunk imports together that are related to each other.\n",
        "*   When importing created modules, like classes, it's best to keep all of the program's modules in one file so you don't need to change the system path.\n",
        "*   Not every module is supported over multiple programming languages.\n",
        "*   If you're having trouble with a particular task, look up modules for your programming languageâ€”you may find something incredibly useful to import.\n",
        "\n",
        "**Interpretting Code**\n",
        "*   \"import\" calls for modules to import\n",
        "*   \"from\" specifies what should be imported from a module rather than importing the entire module\n",
        "*   \"as\" changes how the module is called when it's used in the program\n",
        "*   \"keras\" is a machine learning module for python that simplifies Google's Tensorflow\n",
        "*   \"numpy\" is an array manipulation module for python\n",
        "*   \"matplotlib\" is a data plotting module\n",
        "*   \"sklearn\" is data mining and data analysis module\n",
        "*   \"os\" is a python module for your machine's operating system\n",
        "\n",
        "**External Information**\n",
        "*   [Python Import System](https://docs.python.org/3/reference/import.html)\n",
        "*   [Keras Documentation](https://keras.io)\n",
        "*   [Numpy Documentation](http://www.numpy.org)\n",
        "*   [Matplotlib Documentation](https://matplotlib.org)\n",
        "*   [Sklearn Documentation](https://scikit-learn.org/stable/index.html#)\n",
        "*   [Python Documentation](https://www.python.org)\n",
        "\n",
        "These sources are great for interpretting what modules are being used in this notebook. If there is any uncertainty as to what operation is being done, it never hurts to look up the operation at the documentation's source.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "sdh6EanTCHxL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Suppress Warnings\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"2\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fNliCticDMEr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Variable Initialization & Environmental Variables**\n",
        "\n",
        "This cell suppresses warnings and disables debugging logs from Tensorflow. This is mostly just for preference since the program can operate without this line of code, but it makes the program notifications less annoying.\n",
        "\n",
        "**Vocabulary/Concepts**\n",
        "*   Variable Initialization.......Assigns a value to a variable\n",
        "  *   Variable............................Stores data under a name and type\n",
        "  *   Data..................................Information\n",
        "*   Environmental Variable...A value that affects running process behavior\n",
        "\n",
        "**Execution**\n",
        "\n",
        "Variable initilization sets one variable equal to a value. In this case, an environmental variable is being set to the value \"2\" which will be relayed to Tensorflow in order to prevent debugging and warnings from being displayed. Again, this statement was included as a preference since the notifications can be distracting, but the network can operate without suppressing Tensorflow's warnings.\n",
        "\n",
        "**General**\n",
        "*   Environmental variables can alter the way your program runs so it is important to be aware of how each variable affects the program when coding. \n",
        "*   Variable initialization is a basic computer science operation. It is crucial in almost every program. \n",
        "\n",
        "**Interpretting Code**\n",
        "*   \"os\" refers to the python operating system module\n",
        "*   \"environ['TF_CPP_MIN_LOG_LEVEL']\" specifies the environmental variable being changed\n",
        "*   \"=\" is an operator where the variable on the left side is set equal to the value on the right\n",
        "*   \"2\" is the value that the environmental variable is set to which is one of the modes for tensorflow logging\n",
        "\n",
        "**External Information**\n",
        "*   [Python Operators](https://www.tutorialspoint.com/python/python_basic_operators.htm)\n",
        "*   [Variable Intialization](https://stackoverflow.com/questions/23345554/the-differences-between-initialize-define-declare-a-variable)\n",
        "*   [Environmental Variables](https://en.wikipedia.org/wiki/Environment_variable)\n",
        "*   [Operating System Documentation](https://docs.python.org/2/library/os.html)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "D0qwTu2OCMMG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Load and separate data into X: Features, Y: Labels\n",
        "mnist_data = fashion_mnist.load_data()\n",
        "\n",
        "x = mnist_data[0][0]\n",
        "y = mnist_data[0][1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BkdN0VkZDMvq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Data Representation & Methods**\n",
        "\n",
        "This cell initializes and separates the mnist data into the labels and inputs to later be interpretted by the neural network.\n",
        "\n",
        "**Vocabulary/Concepts**\n",
        "*   Methods......................Operations under a name that accomplish a task\n",
        "*   Labels..........................The identification of data\n",
        "*   Tuples, Arrays, Lists...Series of data\n",
        "\n",
        "\n",
        "**Execution**\n",
        "\n",
        "The first line of code initializes the data as a two-row tuple that contains a two-element tuple on each row using the \".load_data()\" method. Next, x is initialized as the first element in the first tuple and y is initialized as the second element of the first tuple. This separates our labels and images, but there is still more to do before these two are usable by out neural network.\n",
        "\n",
        "**General**\n",
        "*   Methods and objects can be created by the programmer or can come from imported modules. They can be applied to class objects or can be applied using the import calls. Methods also often require parameters (which are placed between the parentheses) and can return a value. In this case, the \".load_data()\" method returns a tuple of tuples.\n",
        "*   There are three types of data in series:\n",
        "  *   Tuples are denoted by brackets, are limited in size, can carry different objects, and cannot be edited once created. \n",
        "  *   Lists are denoted by parentheses, are unlimited in size, can carry different objects, and can be edited once created. \n",
        "  *   Arrays are denoted by brackets and are either created with the Python array module or the Numpy module. They are unlimited in size, carry one type of object, and can be edited once created. Additionally, they're valuable since they can undergo manipulation that affects the entire array.\n",
        "*   Keep in mind that the elements in the tuples inside the tuple are arrays of numbers that represent pixel values\n",
        "*   It is important to note that arrays, lists, and tuples follow a specific rule when they are indexed. For instance, let's assume \"arr\" is an array of 10 integers in sequence from 1 to 10.  arr[0] refers to the first integer in the array: 1. arr[1] refers to the second integer: 2. At the very end, arr[9] refers to 10. arr[10] would throw an error because it is out of bounds. Thus, when indexing or creating one of these three objects, always keep in mind that the index starts counting at [0] and ends at [(range) - 1].\n",
        "*  \"x\" in machine learning always refers to the input data.\n",
        "*  \"y\" in machine leanring always refers to the labels.\n",
        "\n",
        "**Interpretting Code**\n",
        "*   \"mnist_data\" is the tuple of tuples that stores the returned value of \"fashion_mnist.load_data()\"\n",
        "*   \"fashion_mnist\" is the imported dataset from Keras\n",
        "*   \".load_data()\" is a method from Keras that returns data in a tuple of tuples\n",
        "*   \"x\" is the variable that \"mnist_data[0][0]\" is assigned to; \"[0][0]\" denotes that the first element in the first tuple which, according to the Keras documentation, is x_train\n",
        "*   \"y\" is the variable that \"mnist_data[0][1]\" is assigned to; \"[0][1]\" denotes that the second element in the first tuple which, according to the Keras documentation, is y_train\n",
        "\n",
        "**External Information**\n",
        "*   [Lists, Arrays, and Tuples](https://stackoverflow.com/questions/626759/whats-the-difference-between-lists-and-tuples)\n",
        "*   [Array Indexing](https://en.wikipedia.org/wiki/Array_data_structure#Element_identifier_and_addressing_formulas)\n",
        "*   [Methods](https://en.wikipedia.org/wiki/Method_(computer_programming)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "oXRkFEzoCPf8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Set Variables\n",
        "epochs = 50\n",
        "num_classes = 10\n",
        "batch_size = 1028\n",
        "img_rows, img_cols = 28, 28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pOZegAL3DNZM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **More Variable Initialization & ML Variables**\n",
        "\n",
        "This cell initializes more variables that will be used for training and classification.\n",
        "\n",
        "**Vocabulary/Concepts**\n",
        "*   Epochs.................................Times a network runs through an entire dataset\n",
        "*   Classes (Classification)......Number of categories a network can classify data into\n",
        "*   Batches................................A group of training examples. The network can only update after training through all the examples in the batch. Important information from each example is saved for updating until the batch is completed\n",
        "  *   Update..................................Synonym for backpropagate. Backpropagation occurs after each batch during training and will be discussed in the next cell\n",
        "*   Image rows and columns....An image's number of horizontal and vertical lanes which consists of many pixels\n",
        "\n",
        "**Execution**\n",
        "\n",
        "Each line of code is initializing a separate variable which all take the form of integers. For the last line of code, two similar variables are grouped together and are initialized respectively. To do this, variables must be separated by a comma. These variables will be used later to instruct the neural network how long it should run for, what categories to classify data into, how many examples it should update after, and how many inputs it will need to digest.\n",
        "\n",
        "**General**\n",
        "*   You may wonder \"why initialize a variable if it's just a number that can be hard-coded?\" This highlights two more important aspect of variable initialization: labeling and multiple usage.\n",
        "  *   Labeling numbers gives others a better understanding of what is being used. For example, a method that uses \"epochs\" as an input tells the reader more than a method that uses \"50\" as an input.\n",
        "  *   Using a value multiple times without assigning it to a variable can lead future problems. For example, if you use \"50\" everywhere and you want to change all 50s to 40s, you'll have manually change every occurence of 50. If you assign 50 to \"epochs\", you can change the variable's value without manually finding every instance of the variable.\n",
        "*   Group your initialized variables together; they'll be easier to find if you need to change their values.\n",
        "*   Similar variables can be initialized together as seen above.\n",
        "\n",
        "**Interpretting Code**\n",
        "*   \"epochs\" is set to 50. This means the network will run through the entire training dataset 50 times\n",
        "*   \"num_classes\" is set to 10. This means the network must classify an image into one of 10 classes\n",
        "*   \"batch_size\" is set to 1028. This means the network will run through 1028 images before updating\n",
        "*   \"img_rows\" and \"img_cols\" are set to 28. This denotes that each input image is a 28x28 array of pixels which will be important for inputting data into the network\n",
        "\n",
        "**External Information**\n",
        "*   [Epochs, Batches, & Iterations](https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "P3aSCa2ECYHC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Split data into train & test data\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k0Ze3qaVDOIS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Training Data & Testing Data**\n",
        "\n",
        "This cell splits data into training data and test data using the method imported from sklean.model_selection called train_test_split(). Once again, there is more variable initialization.\n",
        "\n",
        "**Vocabulary/Concepts**\n",
        "*   Training.......................Trial runs on training data to fuel backpropagation\n",
        "  *   Backpropagation......Mathematical analysis of loss to reduce future loss. Backpropagation occurs after a batch is completed. It is the source of a network's \"learning\" capabilities\n",
        "  *   Loss...........................Also known as error. Measures how far off the network's classification is from the true value\n",
        "*   Testing.........................Occurs after training to measure how well the machine has learned. Testing is a countermeasure to overfitting\n",
        "  *   Overfitting..................Dilemma that occurs when an algorithm gets extremely good at classifying training data, but performs worse when classifying new data. Essentially, the machine has memorized the training data and ignores the patterns that can apply to new data\n",
        "*   Training data...............Data the algorithm evaluates to backpropagate and improve\n",
        "*   Test data.....................Data the algorithm evaluates so people can measure the algorithms's performance\n",
        "*   Seed............................Ensures both data and labels are randomly split the same way since the labels must correspond to their data. Otherwise, the data will be nonsensical\n",
        "  \n",
        "**Execution**\n",
        "\n",
        "The \"train_test_split()\" method from sklearn takes \"x\", \"y\", \".33\", and \"42\" as parameters to return four arrays which are initialized a \"x_train\", \"x_test\", \"y_train\", and \"y_test\". These arrays will be used later to train the network to classify images optimally. However, the data is still not in a usable form.\n",
        "\n",
        "**General**\n",
        "*   Training data should be around twice as large as test data.\n",
        "*   Don't let your machine train for too many epochs otherwise you risk overfitting\n",
        "*   To gauge when your algorithm begins to overfit, keep track of metrics by printing out information as the machine trains\n",
        "\n",
        "**Interpretting Code**\n",
        "*   To return four arrays, \"train_test_split()\" is taking four parameters:\n",
        "  *   \"x\" refers to the images\n",
        "  *   \"y\" refers to the image labels\n",
        "  *   \"test_size=.33\" refers to what proportion of the data should be test data (and consequentially what proportion should be training data)\n",
        "  *   \"random_state=42\" is a seed for predictable randomness\n",
        "*   \"x_train\", the training images, are assigned to the first element of the array returned by \"train_test_split()\"\n",
        "*   \"x_test\", the testing images, are assigned to the second element of the array returned by \"train_test_split()\"\n",
        "*   \"y_train\", the training labels, are assigned to the third element of the array returned by \"train_test_split()\"\n",
        "*   \"y_test\", the testing labels, are assigned to the fourth element of the array returned by \"train_test_split()\"\n",
        "\n",
        "**External Information**\n",
        "*   [Scikit Learn's test_train_split() ](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
        "*   [Training and Test Data](https://www.quora.com/What-is-a-training-data-set-test-data-set-in-machine-learning-What-are-the-rules-for-selecting-them)\n",
        "*   [Backpropagation](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/)\n",
        "*   [Overfitting](https://elitedatascience.com/overfitting-in-machine-learning)\n",
        "*   [Random Seed](https://en.wikipedia.org/wiki/Random_seed)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "xDV8Lbu3CYg_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Making changes according to Backend\n",
        "if K.image_data_format() == \"channels first\":\n",
        "  x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "  x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "else:\n",
        "  x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "  x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "  input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6e_afaO1DO5g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Data Formatting**\n",
        "\n",
        "This cell reshapes image data depending on the image data format from Keras's backend, also known as the data access layer. Without this cell, the network may not operate properly due to misunderstood data.\n",
        "\n",
        "**Vocabulary/Concepts**\n",
        "*   Backend..............Data accessing layer to any piece of software.\n",
        "*   Channels.............Channels of an image. A typical colored image has three channels for red, blue, and green colors. In this example, there is only one channel since the images are black and white.\n",
        "*   If statements.......Prompted by \"if\". They compare two objects and validate whether the comparison is true or false. If the comparison is true, the code directly below the statement is executed. If the comparison is false, the code directly below the statement is skipped.\n",
        "*   Else statements...Prompted by \"else\" and can only happen after \"if statements\". These execute when the if statement is false, but something else must be executed that wouldn't normally be executed had the \"if statement\" been true.\n",
        "*   Data Cleaning........Preparing data for analysis which includes formatting, checking for false records, checking for abnormalities, uniforming, etc.\n",
        "\n",
        "**Execution**\n",
        "\n",
        "The code first checks the demanded format by Keras. If it is on the \"channels first\" option, the image data is reshaped with the channel number before the rows and columns of the image. If it is not, the the channel number comes after the rows and columns of the image. This code just ensures that the network will understand the data it receives based on the backend that was used to construct it.\n",
        "\n",
        "**General**\n",
        "*   Formatting data and data cleaning is a necessary chore for machine learning to take place; abnormalities in formatting will result in poor results or errors. Luckily, the MNIST datasets are pre-cleaned, but in many cases, formatting and cleaning involve a lot more than rearranging arrays.\n",
        "*   Backends, like environmental variables and documentation, are important to check to validate your code. You may have the correct data, but you may be implementing in a way that is incompatible with the backend.\n",
        "\n",
        "**Interpretting Code**\n",
        "*   \"if\" begins an \"if statement\" that determines whether or not Keras's \"image_data_format()\" is equal to \"channels first\" or not\n",
        "*   \"x_train\" and \"x_test\" are reinitialized with the same contents but different shape using the \"reshape()\" method from numpy. The channel number \"1\" comes first under the \"if statement\"\n",
        "*   \"else\" begins an \"else statement\" that executes code if the \"if statement\" is false\n",
        "*   \"x_train\" and \"x_test\" are reinitialized with the same contents but different shape using the \"reshape()\" method from numpy. The channel number \"1\" comes last under the \"else statement\"\n",
        "*   \"input_shape\" is also initialized which refers to the image rows, columns, and channels\n",
        "\n",
        "**External Information**\n",
        "*   [If Statements](https://codehs.gitbooks.io/introcs/content/Programming-with-Karel/if-else-statements.html)\n",
        "*   [Backends](https://en.wikipedia.org/wiki/Front_and_back_ends)\n",
        "*   [Data Cleaning](https://towardsdatascience.com/data-cleaning-101-948d22a92e4)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "nqcMtQkTCYwX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Set astype on data to 'float32'\n",
        "x_train = x_train.astype(\"float32\")\n",
        "x_test = x_test.astype(\"float32\")\n",
        "x_train /= 225\n",
        "x_test /= 224\n",
        "#Notes\n",
        "#*Not converting array types into floats increases loss\n",
        "#*Division seems to have no effect"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OtAQa09_DPld",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **More Data Formatting**\n",
        "\n",
        "This cell does more data formatting operations on the image arrays by converting their stored variable types and doing some arraywide division.\n",
        "\n",
        "**Vocabulary/Concepts**\n",
        "*   Data type...Form data takes to represent itself\n",
        "*   Float..........A number with a decimal\n",
        "*   Integer.......A whole number\n",
        "\n",
        "**Execution**\n",
        "\n",
        "The first two lines of code reinitialize \"x_train\" and \"x_test\" once again, except now all of their elements are floats rather than integers. The last two lines of code divide every element in both arrays by 225 and 224 respectively. These floats will let the network make more precise measurements of error by enabling calculations to go below the 1's place.\n",
        "\n",
        "**General**\n",
        "*   Floats are generally more precise than integers.\n",
        "*   There are many data types, but numerical data is the least complicated manipulate with machine learning.\n",
        "\n",
        "**Interpretting Code**\n",
        "*   \".astype()\" is a numpy method that casts elements of an array into a new data type which is taking one parameter:\n",
        "  *   \"'float32'\" denotes what datatype the data should be casted into\n",
        "*   \"/=\" is an operator that divides the variable on the left by the value on the right. Then, it sets the variable equal to the quotient\n",
        "*   The first two lines of code reinitialize \"x_train\" and \"x_test\" into arrays of floats\n",
        "*   The last two lines of code divide \"x_train\" and \"x_test\" by 225 and 224 respectively\n",
        "\n",
        "**External Information**\n",
        "*   [Python Data Types](https://realpython.com/python-data-types/#floating-point-numbers)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "UcAu0spuCY39",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Converting class vector to binary class matrices (one-hot encoding)\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AUwRx0OgDQMa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **One-Hot Encoding**\n",
        "\n",
        "This cell does more data formatting with the labels rather than the image arrays. \n",
        "\n",
        "**Vocabulary/Concepts**\n",
        "*   One-hot encoding...Vector representation for labelling data. For example, [1, 0, 0], [0, 1, 0], [0, 0, 1] are all different identities in a list of three elements\n",
        "\n",
        "**Execution**\n",
        "\n",
        "The \"y_train\" and \"y_test\" array elements are all reinitialized as one-hot encoded labels. This enables for the network's output to be placed into a one-dimensional array which allows for an easy, side-by-side comparison between the one-hot label and one-dimensional output array of the network. The network's job is to make them as identical as possible by reducing loss. After this cell runs, the data is now ready to be used by the network.\n",
        "\n",
        "**General**\n",
        "*   One-hot encoding is typically used to label data because it matches the number of output neurons to the number of classes. This is a representation of data that is good to know when getting into classification problems using machine learning.\n",
        "\n",
        "**Interpretting Code**\n",
        "*  \".to_categorical()\" is a keras.utils method that changes labels into a one-hot representation that is taking two parameters:\n",
        "  *    \"y_train\" and \"y_test\" tell the method what labels need to be encoded \n",
        "  *    \"num_classes\" tess the method how many labels need to created\n",
        "*  Both the training and test labels are being coverted into one-hot representations.\n",
        "\n",
        "**External Information**\n",
        "*   [One-hot encoding](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "gXfYK0htCZAd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Defining the model (Hyper-opt: hyperparameter optimization)\n",
        "# Hyperparams: Kernal size, node amounts, max pool size\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, 5, 5, activation=\"relu\",input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(32, 5, 5, activation=\"relu\",input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation=\"relu\")) # Hidden layer of plain neurons\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation=\"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b7Nvi9TqDQvN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Convolutional Neural Network Structure**\n",
        "\n",
        "This cell builds the convolutional neural network which has some unique requirements compared to other neural networks.\n",
        "\n",
        "**Vocabulary/Concepts**\n",
        "*   Model..........................Synonym for \"neural network\"\n",
        "*   Neurons......................The functional unit of any neural network. Conduct specialized operations on input data.\n",
        "*   Layers..........................Assortments of neurons in parallel layers. Each neuron in a layer has one output. All outputs of one layer is fed into each neuron in the next layer. A layer is usually tied to a specific function\n",
        "  *   Convolution...............Detects features in an image to create a feature map: an image that represents important features of the source image\n",
        "  *   Max Pooling...............Magnifies the feature map into a smaller image where only the most prevalent features are represented\n",
        "  *   Flatten........................\"Flattens\" a multidimensional array into two dimensions\n",
        "  *   Dense.........................A layer of plain neurons that manipulate numerical input\n",
        "  *   Dropout......................Sets a proportion of the inputs going into the next layer as zero. This forces other neurons to learn to prevent overfitting\n",
        "*   Activation Functions...A function within a neuron that manipulates the output of the neuron by determining whether or not the neuron activates\n",
        "  *   Rectified Linear Unit..A good general-use activation function for simple problems\n",
        "  *   Softmax......................Ensures the output of a single neuron is between 0 and 1. Additionally, all neuron outputs will add up to 1. These are desirable for one-hot representation comparisons\n",
        "\n",
        "**Execution**\n",
        "\n",
        "The first line of code makes building a neural network as easy as layering a cake; any layer added to the model after \"model = Sequential()\" is layered above of the previous layer where the first layer added is the input layer. The next five lines after the first line are layers that do additional operations on the image to condense it's information. The next line takes that condensed information and manipulates it with a layer of plain neurons. The dropout layer randomly removes half of the information going into the next layer which helps the neural network learn more in the long run by forcing all neurons to be used over time. Last is the output layer where the outputs of the ten neurons will be placed in an array and compared to one-hot labels.\n",
        "\n",
        "**General**\n",
        "*   When building a network, there is a lot of customization to consider. For instance, why use the \"relu\" activation function when there are plenty of others to use? Why only have eight layers when you can create more or less? Finding the optimal model by manipulating independent variables, like the model structure, is called \"hyperparameter optimization\".\n",
        "*   Convolution always occurs directly before pooling.\n",
        "*   \"relu\" is a good general-use activation function that works well in most circumstances. However, with a more complex or niche problem, it may be replaced with another activation function.\n",
        "*   The \"softmax\" activation function will be used for any output layer when the goal of the network is to classify something using one-hot vector comparisons.\n",
        "*   The number of neurons in the first layer must be equal to the amount of data being put into it. That's why the \"input_shape\" parameter of the method is set equal to our \"input_shape\" that we initialized earlier.\n",
        "*   The number of neurons in the output layer MUST be equal to the number of categories to classify images as. That's why the number of neurons parameter is \"num_classes\" which was also initialized earlier.\n",
        "\n",
        "**Interpretting Code**\n",
        "*   \"model = Sequential()\" affirms that the layers of the neural network will be added in order from the input layer to the output layer. All of these methods are taken from Keras\n",
        "*   \"model.add()\" layers a specified layer on top of the previous layer. This method only takes one parameter of what type of layer should be added, but each layer is created with a method that requires their own unique parameters:\n",
        "*   \"Conv2D\" creates a layer that convolves the image. It's taking five parameters:\n",
        "  *   \"32\" refers to how many channels or feature maps convolution will produce\n",
        "  *   The first \"5\" refers to the length and width of the kernel which slides along the image to detect features for the feature map\n",
        "  *   The next \"5\" refers to how far the kernel slides along the image with each iteration. Thus, the kernel will slide five pixels up, down, left, or right when it is done detecting a feature\n",
        "  *   \"activation=\"relu\"\" sets the activation function to the rectified linear unit\n",
        "  *   \"input_shape=input_shape\" sets the method's input shape equal to the size of our image\n",
        "*   \"MaxPooling2D\" creates a layer that pools the image. It's taking one parameter:\n",
        "  *   \"pool_size=(2,2)\" sets the length and width of the pooling kernel which slides along the image, detects the most important feature out of the 2x2 kernel, then feeds that feature into a new, smaller image\n",
        "*   \"Flatten\" creates a layer that flattens the image into two dimensions. It's taking no parameters\n",
        "*   \"Dense\" creates a layer of normal neurons that don't have a specialized operation beyond data manipulation. It's taking two parameters:\n",
        "  *   \"128\" refers to the number of neurons in the layer. Each neuron will be receiving the outputs of each neuron in the previous layer\n",
        "  *   \"activation=\"relu\"\" sets the activation function to the rectified linear unit\n",
        "*   \"Dropout\" creates a layer that sets a random proportion of the data going into the next layer to zero which forces other neurons to learn patterns. This combats overfitting and it's takine one parameter:\n",
        "  *   \"0.5\" refers to how much of the input data going into the next layer should be set to zero. The elements are chosen randomly, but half of the data will always be zero\n",
        "\n",
        "**External Information**\n",
        "*   [Neurons, Layers, and General Structure](neuralnetworksanddeeplearning.com/chap1.html)\n",
        "*   [Convolution, Pooling, and Convolutional Neural Network Structure](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/)\n",
        "*   [Activation Functions](https://www.quora.com/What-is-the-role-of-the-activation-function-in-a-neural-network-How-does-this-function-in-a-human-neural-network-system)\n",
        "*   [Keras Model Documentation](https://keras.io/models/model/)\n",
        "*   [Sigmoid and Softmax](http://dataaspirant.com/2017/03/07/difference-between-softmax-function-and-sigmoid-function/)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "3gmIfedmCZHp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Compiling the model\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, \n",
        "              optimizer=keras.optimizers.Adadelta(), \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9zvbvK_bDRel",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Compiling**\n",
        "\n",
        "This cell compiles the neural network by providing a menu of common hyperparameter configurations for the user to choose from. Like the structure, these will also vary from network to network depending on the task at hand.\n",
        "\n",
        "**Vocabulary/Concepts**\n",
        "*   Hyperparameters.......The aspects of a neural network that a person can edit; independent variables\n",
        "*   Weights................................Weights are contained in neurons and come in the form of regular weights and biases that respectively multiply and add to input values. These are changed in backpropagation according to loss\n",
        "*   Loss Function......................Function that determines how loss is quantified\n",
        "*   Categorical Crossentropy...A common loss function for classification problems with more than two classes. Loss is calculated logarithmically where a greater difference between the network's classification and the actual classification means a greater loss\n",
        "*   Optimizer.............................A custom set of optimized hyperparameters. \"Adadelta\"  includes:\n",
        "  *   Learning Rate (Alpha).......Determines how dramatically neuron weights are changed in response to loss\n",
        "  *   Learning Rate Decay.........Determines how much the learning rate lessens the more the network learns\n",
        "  *   Weight Decay (Rho)..........Regulates weights by causing weight decay in proportion to its size\n",
        "  *   Fuzz Factor (Epsilon)........A small float that prevents division errors from dividing by zero\n",
        "*   Metrics.................................A measurement to look at in order to judge the performance of the model\n",
        "\n",
        "**Execution**\n",
        "\n",
        "Compiling the model covers general hyperparameters that are necessary for every neural network, but again, can vary from network to network. Each hyperparameter has a different purpose. Most hyperparameters can greatly affect the viability of a neural network.\n",
        "\n",
        "**General**\n",
        "*   There are many optimizers, loss functions, metrics, and other hyperparameters to consider when building a neural network. Neural networks themselves are known for specializing in a task in a non-explicit manner, but these hyperparameters can enable a network to reach certain levels of performance. Hyperparameter optimization ensures that hyperparameters are adjusted to reach maximum levels of performance.\n",
        "\n",
        "**Interpretting Code**\n",
        "*   \"model.compile()\" configures and initializes the rest of the network's hyperparameters.\n",
        "*   \"loss=keras.losses.categorical_crossentropy\" sets the loss function to categorical crossentropy\n",
        "*   \"optimizer=keras.optimizer.Adadelta()\" sets the optimizer to Adadelta, an optimizer that adjusts the learning rate and weight decay according to recent network updates\n",
        "*   \"metrics=['accuracy']\" ensures that the network's accuracy is kept track of to measurement its performance\n",
        "\n",
        "**External Information**\n",
        "*   [Hyperparameter Optimization](https://en.wikipedia.org/wiki/Hyperparameter_optimization)\n",
        "*   [Loss Functions](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html)\n",
        "*   [Keras Optimizers](https://keras.io/optimizers/)\n",
        "*   [Keras Metrics](https://keras.io/metrics/)\n",
        "*   [Other Optimizers](https://www.quora.com/What-are-differences-between-update-rules-like-AdaDelta-RMSProp-AdaGrad-and-AdaM)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "16ngcrOBCZPR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Setting Early Stopping\n",
        "my_callbacks = [EarlyStopping(monitor=\"acc\", patience=5, mode=max)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dj88dxIcDSAs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Callbacks**\n",
        "\n",
        "This cell is in charge of callbacks which run certain functions alongside training. This enables the user to get a view on metrics during runtime, track additional statistics, and stop training early. This callback only focuses on stopping training early which is typically done when a neural network is seeing no improvement.\n",
        "\n",
        "**Vocabulary/Concepts**\n",
        "*   Callback............A set of functions that can be executed at any step during training\n",
        "*   EarlyStopping...A callback that tracks the neural network's performance and stops training if it stops improving\n",
        "\n",
        "**Execution**\n",
        "\n",
        "The \"my_callbacks\" object is initialized to be used later during training. By default, Keras's training method, \".fit()\", includes a callback that returns metrics after each epoch/batch the neural network completes. This will help us track the network's improvement during training to determine if it will produce desired results, if it has overfitted, etc.\n",
        "\n",
        "**General**\n",
        "*   Keras training always keeps track of runtime metrics.\n",
        "*   There are various callbacks with different functions like saving a networks's progress, stopping in response to a certain stimuli, streaming the network's progress, and more. \n",
        "\n",
        "**Interpretting Code**\n",
        "*   \"my_callbacks\" is being initialized as a callback object\n",
        "*   \"EarlyStopping()\" constructs the callback object by taking three parameters:\n",
        "  *   \"monitor=\"acc\"\" lets the function know it will monitor accuracy to measure improvement\n",
        "  *   \"patience=5\" tells the function to wait five epochs no improvement before it stops training\n",
        "  *   \"mode=max\" tells the function to stop training when the monitored value stops increasing as opposed to \"mode=min\" which tells the function to stop training when the monitored value stops decreasing\n",
        "  \n",
        "**External Information**\n",
        "*   [Keras Callbacks](https://keras.io/callbacks/)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Wlxbwi43CZWx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Fitting & Evaluating\n",
        "hist = model.fit(x_train, y_train, \n",
        "                    batch_size=batch_size, \n",
        "                    epochs=epochs, \n",
        "                    verbose=1, \n",
        "                    validation_split=0.3, \n",
        "                    callbacks=my_callbacks)\n",
        "\n",
        "score = model.evaluate(x_test, y_test)\n",
        "\n",
        "print(\"Testing Loss:\", score[0])\n",
        "print(\"Testing Accuracy:\", score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eC2P2fcQDSlG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Training & Testing**\n",
        "\n",
        "By now, the neural network can finally be trained and tested. This cell trains the neural network, saves its training history, uses the trained network to evaluate a new set of test data, saves its test score, then prints out the scores for the user to see.\n",
        "\n",
        "**Vocabulary/Concepts**\n",
        "*   Fitting..................Synonym for \"training\"; Trial runs on test data to fuel backpropagation which mathematically analyzes error to reduce future error. Backpropagation occurs after a batch is run through and is the source of a network's \"learning\" capabilities\n",
        "*   Validation Data...Miniature test data that tests the network at the end of each epoch. Validation data comes from splitting training data again. In scholastic terms, training data is homework, validation data is a quiz, and test data is a major test\n",
        "*   Evaluating...........Synonym for \"testing\"; Occurs after training to measure how well the machine has learned. A countermeasure to overfitting\n",
        "\n",
        "**Execution**\n",
        "\n",
        "The first line trains the network and then saves its history in an object called \"hist\". While the network trains, it will return metrics on its performance. In the next line of code, the fully trained model is tested with the test data that was set aside earlier to measure the validity of the network's performance. The outputs of the test is saved to \"score\" which is then printed out for the user to read in the next two lines. This cell, and the next couple of cells, give the user data to judge the network.\n",
        "\n",
        "**General**\n",
        "*   Evaluating is suppose to test your trained network, but for comparison, you can evaluate your network before you train it to compare the untrained network to the trained network. Just be sure that it isn't working on real-world data that carry consequences for mistakes.\n",
        "*   It's always wise to save the network's history and test score to view later, especially for hyperparameter optimization.\n",
        "\n",
        "**Interpretting Code**\n",
        "*   \"hist\" is a object that's initialized as the history returned by the \".fit()\" method\n",
        "*   \"model.fit()\" is a method from Keras that trains the neural network. It's taking seven parameters:\n",
        "  *   \"x_train\" refers to the training images that will be input into the network\n",
        "  *   \"y_train\" refers to the training labels that will be compared to the network's output\n",
        "  *   \"batch_size=batch_size\" sets the batch size for Keras's training equal to our batch size that we initialized earlier\n",
        "  *   \"epochs=epochs\" sets the epochs for Keras's training equal to our epochs that we also initialized earlier\n",
        "  *   \"verbose=1\" tells Keras how verbose it should be regarding the network's training progress. \"0\" tells Keras to stay silent. \"1\" tells Keras to show a progress bar. \"2\" tells Keras to show a bar per epoch\n",
        "  *   \"validation_split=0.3\" tells Keras to split training data once again into training data and validation data (with corresponding labels). It's exactly like the test_train_split() from sklearn, except this happens inside training\n",
        "  *   \"callbacks=my_callbacks\" sets the callbacks for Keras's training equal to the callbacks we initialized earlier\n",
        "*   \"score\" is a tuple that's initialized to hold the accuracy and loss of the model which is returned by the \".evaluate()\" method\n",
        "*   \"model.evaluate()\" is a method from Keras that tests the neural network. It's taking two parameters:\n",
        "  *   \"x_test\" refers to the test images that were set aside earlier. These will be fed into our trained neural network to judge its performance\n",
        "  *   \"y_test\" refers to the test labels that were set aside earlier. These will also be fed into our trained neural network to judge its performance\n",
        "*   \"print(\"Testing Loss:\", score[0])\" prints the loss of the model from the testing session which is stored as the first element of the \"score\" tuple\n",
        "*   \"print(\"Testing Accuracy:\", score[1])\" prints the accuracy of the model from the testing session which is stored as the second element of the \"score\" tuple\n",
        "\n",
        "**External Information**\n",
        "*   [Testing, Training, and Validation Data](https://stackoverflow.com/questions/2976452/whats-is-the-difference-between-train-validation-and-test-set-in-neural-netwo)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "75JD8mx_CZgZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Model Summary\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Dxj7gxmDUHq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Neural Network Summary**\n",
        "\n",
        "This cell gives a summary of the model that tells the user the shape of the data as it moves through the neural network and the qualities of each layer's neuron parameters which are the neuron's weights and biases.\n",
        "\n",
        "**Vocabulary/Concepts**\n",
        "*   Neuron Parameters...Refers the to weights and biases in a neuron which can be altered by backpropagation but some neuron parameters can be trained and others not\n",
        "\n",
        "**Execution**\n",
        "\n",
        "This line of code simple describes the model the user has built in more depth using ther \".summary()\" method from Keras. This is useful for keeping track of what layers are being used, the output shape of each layer, and the number of neuron parameters each layer has that can be edited.\n",
        "\n",
        "**General**\n",
        "*   Outputs from layer to layer are expected to decrease since classification problems typically classify data into a small number of categories based on a large amount of input data.\n",
        "*   Not every layer has revisable parameters. Instead, they carry out an operation on the outputs of the previous layer.\n",
        "*   Dense layers will typically have the most neuron parameters and account for most of the data manipulation.\n",
        "\n",
        "**Interpretting Code**\n",
        "*   \"model.summary()\" prints out a description of the neural network model that the user has created which quickly calculates the number of neuron parameters in each layer and displays the output shape of each layer. The \".summary()\" method is a useful tool for quick information about a network\n",
        "\n",
        "**External Sources**\n",
        "*   [Neuron Structure](https://www.neuraldesigner.com/blog/perceptron-the-main-component-of-neural-networks)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "qGbLPDUcCZoi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Plotting training accuracy & validation accuracy\n",
        "epoch_list = list(range(1, len(hist.history['acc']) + 1))\n",
        "plt.plot(epoch_list, hist.history['acc'], epoch_list, hist.history['val_acc'])\n",
        "plt.legend((\"Training Accuracy\", \"Validation Accuracy\"))\n",
        "plt.show"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eN6tUCUYDUny",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Visualizing Metrics**\n",
        "\n",
        "This cell creates a graph to visualize the development of our network over each epoch with the help of a library called Matplotlib.\n",
        "\n",
        "**Vocabulary/Concepts**\n",
        "*   Convergence...............When the changes of the metrics in a neural network (like loss or accuracy) approach zero, the network is \"converging\". A network reaches convergence when the metrics start to plateau over epochs; they begin to reach a limit\n",
        "*   Training Accuracy.......How accurate the network is at classifying training data\n",
        "*   Validation Accuracy....How accurate the network is at classifying validation data\n",
        "\n",
        "**Execution**\n",
        "\n",
        "The first line of code initializes \"epoch_list\" as a list of numbers starting from 1 to the total number of epochs plus one. Second, data is stored on a chart using Matplotlib where the training accuracy and validation accuracy are plotted with respect to the number of epochs. Then, a legend is created on the chart which denotes the dependent variables: \"Training Accuracy\" and \"Validation Accuracy\". Lastly, the plot is shown. This tool, like the summary and callbacks, are useful in comparing neural networks for hyperparameter optimization or judging a network by visualizing metrics.\n",
        "\n",
        "**General**\n",
        "*   When plotting, it is nice to include a legend and title so readers can understand what data is being plotted.\n",
        "*   \"plt.show\" is necessary to display a graphic of the chart. From there, the chart can be saved as an image, exported, printed, etc.\n",
        "\n",
        "**Interpretting Code**\n",
        "*   \"epoch_list\" is a list that will store epoch numbers as individual elements\n",
        "*   \"list()\" creates a list of elements. The elements are specified by \"range(1, len(hist.history['acc']) + 1))\". Essentially, every integer inclusively between 1 and the length of the \"hist.history['acc']\" array plus one (which should be 50) becomes an element in the list\n",
        "*   \"plt.plot()\" is a Matplotlib method that stores data in a plot. It's taking four parameters that come in pairs:\n",
        "  *   \"epoch_list\" is the list that was initialized earlier. This series of integers will serve as the x axis of the plot for both \"hist.history['acc']\" and \"hist.history['val_acc']\" which is why \"epoch_list\" appears twice\n",
        "  *   \"hist.history['acc']\" is an array that stores the accuracy of the neural network from epoch to epoch. This is a dependent variable that will be plotted on the y axis\n",
        "  *   \"hist.history['val_acc']\" is an array that stores the validation accuracy of the neural network from epoch to epoch. This is also a dependent variable that will be plotted on the y axis\n",
        "*   \"plt.legend()\" is a Matplotlib method that creates a legend on the chart. It's taking one parameter:\n",
        "  *   \"(\"Training Accuracy\", \"Validation Accuracy\")\" is a tuple whose two elements refer to the previously plotted pairs. The first element of the tuple tells Matplotlib that the first pair of independent and dependent variables are measuring training accuracy. The second element tells Matplotlib that the second pair of variables measure validation accuracy.\n",
        "*   \"plt.show\" is Matplotlib method that is necessary for showing the chart the user created beforehand. From there, the chart can be saved as an image, printed, exported, etc.\n",
        "\n",
        "**External Information**\n",
        "*   [Convergent Series](https://en.wikipedia.org/wiki/Convergent_series)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "HeFpl_byBIK9",
        "colab_type": "code",
        "outputId": "6124c2f5-e46f-4995-edf8-022467dce8e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2747
        }
      },
      "cell_type": "code",
      "source": [
        "#Entire Program\n",
        "\n",
        "#Import necessary libraries\n",
        "import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n",
        "\n",
        "#Suppress Warnings\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"2\"\n",
        "\n",
        "#Load and separate data into X: Features, Y: Labels\n",
        "mnist_data = fashion_mnist.load_data()\n",
        "\n",
        "x = mnist_data[0][0]\n",
        "y = mnist_data[0][1]\n",
        "\n",
        "#Set Variables\n",
        "epochs = 50\n",
        "num_classes = 10\n",
        "batch_size = 1028\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "#Split data into train & test data\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
        "\n",
        "#Making changes according to Backend\n",
        "if K.image_data_format() == \"channels first\":\n",
        "  x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "  x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "else:\n",
        "  x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "  x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "  input_shape = (img_rows, img_cols, 1)\n",
        "  \n",
        "#Set astype on data to 'float32'\n",
        "x_train = x_train.astype(\"float32\")\n",
        "x_test = x_test.astype(\"float32\")\n",
        "x_train /= 225\n",
        "x_test /= 224\n",
        "#Notes\n",
        "#*Not converting array types into floats increases loss\n",
        "#*Division seems to have no effect\n",
        "\n",
        "#Converting class vector to binary class matrices (one-hot encoding)\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "#Defining the model (Hyper-opt: hyperparameter optimization)\n",
        "# Hyperparams: Kernal size, node amounts, max pool size\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, 5, 5, activation=\"relu\",input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(32, 5, 5, activation=\"relu\",input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation=\"relu\")) # Hidden layer of plain neurons\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation=\"softmax\"))\n",
        "\n",
        "#Compiling the model\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, \n",
        "              optimizer=keras.optimizers.Adadelta(), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Setting Early Stopping\n",
        "my_callbacks = [EarlyStopping(monitor=\"acc\", patience=5, mode=max)]\n",
        "\n",
        "#Fitting & Evaluating\n",
        "hist = model.fit(x_train, y_train, \n",
        "                    batch_size=batch_size, \n",
        "                    epochs=epochs, \n",
        "                    verbose=1, \n",
        "                    validation_split=0.3, \n",
        "                    callbacks=my_callbacks)\n",
        "\n",
        "score = model.evaluate(x_test, y_test)\n",
        "\n",
        "print(\"Testing Loss:\", score[0])\n",
        "print(\"Testing Accuracy:\", score[1])\n",
        "\n",
        "#Model Summary\n",
        "model.summary()\n",
        "\n",
        "#Plotting training accuracy & validation accuracy\n",
        "epoch_list = list(range(1, len(hist.history['acc']) + 1))\n",
        "plt.plot(epoch_list, hist.history['acc'], epoch_list, hist.history['val_acc'])\n",
        "plt.legend((\"Training Accuracy\", \"Validation Accuracy\"))\n",
        "plt.show"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 8us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 4s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (5, 5), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:60: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (5, 5), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:511: RuntimeWarning: EarlyStopping mode <built-in function max> is unknown, fallback to auto mode.\n",
            "  RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 28140 samples, validate on 12060 samples\n",
            "Epoch 1/50\n",
            "28140/28140 [==============================] - 6s 202us/step - loss: 1.7234 - acc: 0.3839 - val_loss: 0.9590 - val_acc: 0.6661\n",
            "Epoch 2/50\n",
            "28140/28140 [==============================] - 1s 32us/step - loss: 0.9331 - acc: 0.6548 - val_loss: 0.7393 - val_acc: 0.7017\n",
            "Epoch 3/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.7323 - acc: 0.7244 - val_loss: 0.6557 - val_acc: 0.7582\n",
            "Epoch 4/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.6555 - acc: 0.7553 - val_loss: 0.6602 - val_acc: 0.7527\n",
            "Epoch 5/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.6149 - acc: 0.7720 - val_loss: 0.5360 - val_acc: 0.8037\n",
            "Epoch 6/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.5685 - acc: 0.7875 - val_loss: 0.5189 - val_acc: 0.8042\n",
            "Epoch 7/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.5488 - acc: 0.8002 - val_loss: 0.5087 - val_acc: 0.8095\n",
            "Epoch 8/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.5242 - acc: 0.8077 - val_loss: 0.4710 - val_acc: 0.8285\n",
            "Epoch 9/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.4985 - acc: 0.8201 - val_loss: 0.4382 - val_acc: 0.8428\n",
            "Epoch 10/50\n",
            "28140/28140 [==============================] - 1s 35us/step - loss: 0.4840 - acc: 0.8246 - val_loss: 0.4372 - val_acc: 0.8432\n",
            "Epoch 11/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.4655 - acc: 0.8338 - val_loss: 0.4321 - val_acc: 0.8363\n",
            "Epoch 12/50\n",
            "28140/28140 [==============================] - 1s 35us/step - loss: 0.4534 - acc: 0.8363 - val_loss: 0.4326 - val_acc: 0.8452\n",
            "Epoch 13/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.4409 - acc: 0.8435 - val_loss: 0.4024 - val_acc: 0.8566\n",
            "Epoch 14/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.4292 - acc: 0.8437 - val_loss: 0.4030 - val_acc: 0.8540\n",
            "Epoch 15/50\n",
            "28140/28140 [==============================] - 1s 35us/step - loss: 0.4142 - acc: 0.8520 - val_loss: 0.4000 - val_acc: 0.8546\n",
            "Epoch 16/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.4046 - acc: 0.8542 - val_loss: 0.4209 - val_acc: 0.8424\n",
            "Epoch 17/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.3973 - acc: 0.8561 - val_loss: 0.3813 - val_acc: 0.8604\n",
            "Epoch 18/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.3924 - acc: 0.8588 - val_loss: 0.3795 - val_acc: 0.8583\n",
            "Epoch 19/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.3822 - acc: 0.8616 - val_loss: 0.3886 - val_acc: 0.8566\n",
            "Epoch 20/50\n",
            "28140/28140 [==============================] - 1s 35us/step - loss: 0.3728 - acc: 0.8660 - val_loss: 0.3633 - val_acc: 0.8666\n",
            "Epoch 21/50\n",
            "28140/28140 [==============================] - 1s 35us/step - loss: 0.3642 - acc: 0.8679 - val_loss: 0.3483 - val_acc: 0.8722\n",
            "Epoch 22/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.3637 - acc: 0.8678 - val_loss: 0.3421 - val_acc: 0.8765\n",
            "Epoch 23/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.3576 - acc: 0.8698 - val_loss: 0.3375 - val_acc: 0.8761\n",
            "Epoch 24/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.3446 - acc: 0.8746 - val_loss: 0.3630 - val_acc: 0.8648\n",
            "Epoch 25/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.3457 - acc: 0.8755 - val_loss: 0.3360 - val_acc: 0.8737\n",
            "Epoch 26/50\n",
            "28140/28140 [==============================] - 1s 35us/step - loss: 0.3364 - acc: 0.8780 - val_loss: 0.3587 - val_acc: 0.8687\n",
            "Epoch 27/50\n",
            "28140/28140 [==============================] - 1s 35us/step - loss: 0.3352 - acc: 0.8792 - val_loss: 0.3274 - val_acc: 0.8808\n",
            "Epoch 28/50\n",
            "28140/28140 [==============================] - 1s 35us/step - loss: 0.3318 - acc: 0.8804 - val_loss: 0.3255 - val_acc: 0.8772\n",
            "Epoch 29/50\n",
            "28140/28140 [==============================] - 1s 35us/step - loss: 0.3282 - acc: 0.8837 - val_loss: 0.3305 - val_acc: 0.8760\n",
            "Epoch 30/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.3211 - acc: 0.8815 - val_loss: 0.3252 - val_acc: 0.8820\n",
            "Epoch 31/50\n",
            "28140/28140 [==============================] - 1s 35us/step - loss: 0.3150 - acc: 0.8853 - val_loss: 0.3314 - val_acc: 0.8782\n",
            "Epoch 32/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.3083 - acc: 0.8867 - val_loss: 0.3607 - val_acc: 0.8706\n",
            "Epoch 33/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.3060 - acc: 0.8877 - val_loss: 0.3229 - val_acc: 0.8821\n",
            "Epoch 34/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.3022 - acc: 0.8892 - val_loss: 0.3130 - val_acc: 0.8857\n",
            "Epoch 35/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.2976 - acc: 0.8904 - val_loss: 0.3393 - val_acc: 0.8750\n",
            "Epoch 36/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.2963 - acc: 0.8920 - val_loss: 0.3157 - val_acc: 0.8857\n",
            "Epoch 37/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.2984 - acc: 0.8920 - val_loss: 0.3105 - val_acc: 0.8867\n",
            "Epoch 38/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.2885 - acc: 0.8931 - val_loss: 0.3014 - val_acc: 0.8900\n",
            "Epoch 39/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.2840 - acc: 0.8961 - val_loss: 0.3092 - val_acc: 0.8868\n",
            "Epoch 40/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.2855 - acc: 0.8953 - val_loss: 0.3068 - val_acc: 0.8887\n",
            "Epoch 41/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.2893 - acc: 0.8937 - val_loss: 0.3004 - val_acc: 0.8874\n",
            "Epoch 42/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.2772 - acc: 0.8981 - val_loss: 0.3336 - val_acc: 0.8788\n",
            "Epoch 43/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.2771 - acc: 0.9002 - val_loss: 0.3001 - val_acc: 0.8925\n",
            "Epoch 44/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.2715 - acc: 0.8990 - val_loss: 0.3219 - val_acc: 0.8826\n",
            "Epoch 45/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.2729 - acc: 0.8984 - val_loss: 0.3000 - val_acc: 0.8888\n",
            "Epoch 46/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.2675 - acc: 0.9020 - val_loss: 0.3003 - val_acc: 0.8879\n",
            "Epoch 47/50\n",
            "28140/28140 [==============================] - 1s 35us/step - loss: 0.2623 - acc: 0.9014 - val_loss: 0.2955 - val_acc: 0.8948\n",
            "Epoch 48/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.2641 - acc: 0.9023 - val_loss: 0.3023 - val_acc: 0.8905\n",
            "Epoch 49/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.2597 - acc: 0.9062 - val_loss: 0.2956 - val_acc: 0.8928\n",
            "Epoch 50/50\n",
            "28140/28140 [==============================] - 1s 34us/step - loss: 0.2579 - acc: 0.9061 - val_loss: 0.3129 - val_acc: 0.8881\n",
            "19800/19800 [==============================] - 2s 77us/step\n",
            "Testing Loss: 0.31902255264496565\n",
            "Testing Accuracy: 0.889393939418022\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 32)        832       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 32)          25632     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 93,418\n",
            "Trainable params: 93,418\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f9345d2ef28>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}